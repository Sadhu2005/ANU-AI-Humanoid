# ANU-
Artificial Neural Univers   
ANU 6.0 - Artificial Neural Universe ğŸ¤–
<p align="center">
<img src="https://www.google.com/search?q=https://placehold.co/600x300/134e4a/f5f5f4%3Ftext%3DANU%2B6.0%26font%3Dinter" alt="ANU 6.0 Project Banner">
</p>

<p align="center">
<strong>An AI-powered humanoid robot designed to be a personalized mentor and an intelligent friend for rural students in India.</strong>
<br />
<br />
<img src="https://www.google.com/search?q=https://img.shields.io/badge/Status-In%2520Development-blue" alt="Status">
<img src="https://www.google.com/search?q=https://img.shields.io/badge/Python-3.9%252B-blueviolet" alt="Python Version">
<img src="https://www.google.com/search?q=https://img.shields.io/badge/Platform-Raspberry%2520Pi%25205-orange" alt="Platform">
<img src="https://www.google.com/search?q=https://img.shields.io/badge/License-MIT-green" alt="License">
</p>

ğŸ¯ Our Mission
To bridge the educational and digital divide for students in rural Karnataka by providing an accessible, engaging, and distraction-free AI learning companion. ANU 6.0 aims to build English fluency, foster confidence, and become a gateway to technology and information for students and their households.

This project was initiated by the EvoBot Crew at the Coorg Institute of Technology, Ponnampet.

ğŸ§ The Problem
Rural students face significant hurdles in their educational journey:

Lack of Conversational Practice: No environment to practice spoken English, limiting fluency.

The Distraction Dilemma: Mobile phones, while a resource, are a primary source of distraction.

Resource Scarcity: Limited access to personalized, high-quality teaching aids.

The Foundational Gap: A weak foundation in English creates barriers to higher education and careers in technology.

âœ¨ Our Solution: ANU 6.0
ANU 6.0 is a 17-DOF humanoid robot that acts as a physical, AI-powered mentor. It provides a focused, interactive, and bilingual (Kannada & English) learning experience, adapting to each student's unique pace and needs. It's a friend to practice with, a teacher to learn from, and a tool that makes advanced technology accessible and fun.

Key Features
ğŸ—£ï¸ Bilingual Conversation: Fluent in both Kannada and English for natural interaction.

ğŸ“ Personalized Learning Paths: Assesses student levels and creates custom lesson plans.

ğŸ¤– Physical & Engaging: Performs gestures like waving and hugging to create a strong, friendly bond.

ğŸŒ Hybrid AI Brain: Functions offline with on-device models and syncs with powerful cloud APIs when online.

ğŸ‘€ Computer Vision: Uses OpenCV for face recognition and environmental awareness.

ğŸ“µ Distraction-Free: A dedicated device for learning, free from the distractions of mobile phones.

ğŸš€ Project Architecture
The system follows a modular, three-stage flow:

Perception (Input): The robot gathers data using its webcam (visuals), microphone (voice commands), and environmental sensors (proximity, presence).

Processing (The Brain): The Raspberry Pi 5 processes this data. It transcribes speech, analyzes images, and uses its hybrid AI core (local models + cloud APIs) to make decisions.

Actuation (Output): The brain sends commands to the PCA9685 servo driver to perform physical actions and to the speaker to generate verbal responses.

ğŸ“ Directory Structure
The repository is organized to separate concerns, making development and maintenance clean and scalable.

anu-6.0/
â”‚
â”œâ”€â”€ ğŸ¤– robot_brain/                # All code that runs on the Raspberry Pi
â”‚   â”œâ”€â”€ main.py                     # Main application entry point
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies for the robot
â”‚   â”œâ”€â”€ .env.example                # Example environment variables
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                       # Core system modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ state_manager.py        # Manages the robot's current state (e.g., listening, speaking, moving)
â”‚   â”‚   â””â”€â”€ connectivity_manager.py # Handles online/offline status and server communication
â”‚   â”‚
â”‚   â”œâ”€â”€ modules/                    # Individual functionality modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ speech_processing/      # Handles STT and TTS
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ offline_stt.py      # Vosk for local speech-to-text
â”‚   â”‚   â”‚   â””â”€â”€ online_tts.py       # Google/API-based text-to-speech
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ai_core/                # The AI decision-making brain
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ offline_llm.py      # Small, local LLM for offline responses
â”‚   â”‚   â”‚   â””â”€â”€ online_llm_api.py   # Handles API calls to Gemini, etc.
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ vision/                 # OpenCV and camera functionalities
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ face_recognition.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ motion/                 # Controls physical movements
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ servo_control.py    # Interface with PCA9685 driver
â”‚   â”‚       â””â”€â”€ actions.py          # Defines complex actions (hug, wave, dance)
â”‚   â”‚
â”‚   â””â”€â”€ logs/                       # For storing runtime logs
â”‚       â””â”€â”€ robot.log
â”‚
â”œâ”€â”€ ğŸŒ server/                     # (Optional) Backend server code for online mode
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ› ï¸ hardware/                    # Hardware schematics, wiring diagrams, and parts list
â”‚   â”œâ”€â”€ ANU_6.0_BOM.csv             # Bill of Materials
â”‚   â””â”€â”€ wiring_diagram.png
â”‚
â”œâ”€â”€ ğŸ“š docs/                        # Project documentation
â”‚   â”œâ”€â”€ architecture.md
â”‚   â””â”€â”€ setup_guide.md
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

âš™ï¸ Getting Started (Robot Setup)
These instructions will get a copy of the robot's brain running on your Raspberry Pi 5.

Prerequisites
Raspberry Pi 5 (8GB RAM recommended) with Raspberry Pi OS (64-bit).

Python 3.9 or newer.

All hardware components (servos, drivers, camera, etc.) connected.

Internet connection (for initial setup).

Installation
Clone the repository:

git clone [https://github.com/your-username/anu-6.0.git](https://github.com/your-username/anu-6.0.git)
cd anu-6.0/robot_brain

Create a virtual environment:

python3 -m venv .venv
source .venv/bin/activate

Install dependencies:

pip install -r requirements.txt

Set up environment variables:

Copy the example file:

cp .env.example .env

Edit the .env file and add your API keys for online services (like Gemini).

# .env
GEMINI_API_KEY="YOUR_API_KEY_HERE"

Running the Robot
Execute the main script:

python main.py
